{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db11d4fe",
   "metadata": {},
   "source": [
    "## Pytorch Fundamentals - 00\n",
    "https://www.youtube.com/watch?v=V_xro1bcAuA&t=2598s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b0290fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658cd622",
   "metadata": {},
   "source": [
    "## Pytorch sensors \n",
    "Created using `torch.Tensor()`\n",
    "https://docs.pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7151a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar tensor\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b70d436f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim  # number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e8e4a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()  # get the value as a standard Python number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "817ecd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector tensor\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dd787fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93bdbfef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72a3ce16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.,  8.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.Tensor([[7, 8], \n",
    "                        [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b589c4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim #ndim = elements in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4a3bb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 10.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc85e9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "47832387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [3., 6., 9.],\n",
       "         [2., 4., 5.]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.Tensor([[[1, 2, 3], \n",
    "                        [3, 6, 9], \n",
    "                        [2, 4, 5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e8bd6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0b1405a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "491b25ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [3., 6., 9.],\n",
       "        [2., 4., 5.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7e87defe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MY_TENSOR = torch.Tensor([[[[1, 2, 3], \n",
    "                            [2, 3, 4],\n",
    "                            [5, 6, 7]]]])\n",
    "MY_TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a383c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MY_TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b00ad",
   "metadata": {},
   "source": [
    "### Random Tensors\n",
    "https://youtu.be/V_xro1bcAuA?si=g-yVMRmg3KtPZYm6&t=5865\n",
    "\n",
    "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`\n",
    "\n",
    "https://docs.pytorch.org/docs/main/generated/torch.rand.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6c013da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8184, 0.6272, 0.7180, 0.7172],\n",
       "        [0.3544, 0.0741, 0.9714, 0.5400],\n",
       "        [0.2455, 0.1292, 0.6825, 0.2549]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cda3cde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c2c4089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2657780d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))  # height, width, color_channels (R, G, B)\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867cd6af",
   "metadata": {},
   "source": [
    "## Zeros and ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "91349eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c9e731b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros * random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0a4454f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7f00288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9957e79",
   "metadata": {},
   "source": [
    "### Creating a range of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3928b815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange()\n",
    "one_to_ten = torch.arange(start=1, end=11, step=1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bef83c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53471d8",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "**Note** Tensor datatypes is one of the three big errors you'll run into with PyTorch and deep learning\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a9b98bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "dtype=torch.float32, #datatype - precision in computing, how much detail is stored in memory\n",
    "device=None, # What device is the tensor stored on?\n",
    "requires_grad=False) # whether or not to track gradients for this tensor's operations\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a37f9cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd3edf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33ad6b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = float_16_tensor * float_32_tensor # becomes float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0882bc3",
   "metadata": {},
   "source": [
    "## Ints\n",
    "https://youtu.be/V_xro1bcAuA?si=FeZ6J8jf4MvAp_Zh&t=7409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "743f5976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "07b86b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = float_32_tensor * int_32_tensor\n",
    "y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e3f15",
   "metadata": {},
   "source": [
    "### Getting info from tensors\n",
    "\n",
    "1. Tensors not right datatype - to get datatype from a tensor, can use tensor.dtype\n",
    "2. Tensors not right shape - to get shape from a tensor, can use tensor.shape\n",
    "3. Tensors not on the right device - to get device from a tensor, can use tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b6dd84da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4495, 0.6048, 0.8725, 0.0307],\n",
       "        [0.2184, 0.3815, 0.0757, 0.8846],\n",
       "        [0.5386, 0.1174, 0.9825, 0.2161]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4aba7ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4495, 0.6048, 0.8725, 0.0307],\n",
      "        [0.2184, 0.3815, 0.0757, 0.8846],\n",
      "        [0.5386, 0.1174, 0.9825, 0.2161]])\n",
      "Datatype: torch.float32\n",
      "Shape: torch.Size([3, 4])\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(some_tensor)\n",
    "print(f\"Datatype: {some_tensor.dtype}\")\n",
    "print(f\"Shape: {some_tensor.shape}\")\n",
    "print(f\"Device: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fe0488",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1dbda6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and add 10 to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b0a7ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply tensor by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "40b6a1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide tensor by 10\n",
    "tensor / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "45ccaf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract 10 from tensor\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c035bedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out PyTorch in-built functions\n",
    "torch.mul(tensor, 10)  # multiply tensor by 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1253b1ae",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "https://youtu.be/V_xro1bcAuA?si=-YlZWxh2QmpDqDR-&t=8269\n",
    "\n",
    "Two main ways of performing multiplication in neural networks and deep learning.\n",
    "\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8e9342b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2117b725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1d9cf3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication by hand\n",
    "1*1 + 2*2 + 3*3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3573e0b9",
   "metadata": {},
   "source": [
    "### One of the most common erros in deep learning: Shape Errors\n",
    "There are two rules that performing matrix multiplication needs to satisfy:\n",
    "1. The **inner dimensions** must match:\n",
    "* `(3, 2) @ (3, 2)` won't work\n",
    "* `(2, 3) @ (3, 2)` will work \n",
    "* `(3, 2) @ (2, 3)` will work\n",
    "\n",
    "2. The resulting matrix has the shape of the **outer dimensions**\n",
    "* `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    "* `(3, 2) @ (2, 3)` -> `(3, 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a988019",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4085228635.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  this will result in an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "#torch.matmul(torch.rand(3, 2), torch.rand(3, 2)) #  this will result in an error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62131045",
   "metadata": {},
   "source": [
    "# Shapes for matrix multiplication - T, Transpose\n",
    "http://matrixmultiplication.xyz/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1def2c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11],   \n",
    "                         [9, 12]])\n",
    "# torch.mm(tensor_A, tensor_B)  # torch.mm is torch.matmul - will result in a shape error\n",
    "\n",
    "# adjust shapes - transpose tensor_B\n",
    "torch.mm(tensor_A, tensor_B.T)  # .T is transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b8c1c7",
   "metadata": {},
   "source": [
    "## Finding the min, max, mean, sum etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "048efdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d5125ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "torch.min(x)\n",
    "x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bed68b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "torch.max(x)\n",
    "x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3bedd983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find mean\n",
    "torch.mean(x.float()) # long wrong datatype for this function\n",
    "x.type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c42e005b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40.)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find median\n",
    "torch.median(x.float())\n",
    "x.type(torch.FloatTensor).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd9a36b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(450)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find sum\n",
    "torch.sum(x)\n",
    "x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c589bd",
   "metadata": {},
   "source": [
    "# Find the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3b8d0b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmin()  # index of min value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9480044a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the maximum value\n",
    "x.argmax()  # index of max value\n",
    "x[x.argmax()]  # value at max index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b5fab3",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing, and unsqueezing tensors\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other vertical stack (vstack) or horizontal stock (hstack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f2b022ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.Size([9]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "# import torch\n",
    "\n",
    "x = torch.arange(1, 10)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "953888c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5, 2, 3, 4, 5, 6, 7, 8, 9]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 9)  # add an extra dimension, must keep same number of elements (9) - will work for (9, 1), multiples of size of tensor\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dd72889e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5, 2, 3, 4, 5, 6, 7, 8, 9]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(1, 9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "381667bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5, 2, 3, 4, 5, 6, 7, 8, 9]]), tensor([5, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x too because they share the same memory\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bf5e8371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5, 5, 5, 5],\n",
       "         [2, 2, 2, 2],\n",
       "         [3, 3, 3, 3],\n",
       "         [4, 4, 4, 4],\n",
       "         [5, 5, 5, 5],\n",
       "         [6, 6, 6, 6],\n",
       "         [7, 7, 7, 7],\n",
       "         [8, 8, 8, 8],\n",
       "         [9, 9, 9, 9]]),\n",
       " torch.Size([9, 4]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=1)  # dim=0 stacks on top of each other, dim=1 stacks side by side\n",
    "x_stacked, x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac58f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5, 2, 3, 4, 5, 6, 7, 8, 9]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://youtu.be/V_xro1bcAuA?si=0wsltx79eC2Nbr3P&t=11490\n",
    "# torch.squeeze() - removes all single dimensions from a tensor\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "949a83a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped_squeezed = x_reshaped.squeeze()\n",
    "x_reshaped_squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0bc52def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target: tensor([5, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Previous shape: torch.Size([9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[5, 2, 3, 4, 5, 6, 7, 8, 9]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.unsqueeze() - adds a single dimension to a tensor at a specified dimension\n",
    "print(f\"Previous target: {x_reshaped_squeezed}\")\n",
    "print(f\"Previous shape: {x_reshaped_squeezed.shape}\")\n",
    "\n",
    "# Add an extra dimension\n",
    "x_reshaped_unsqueezed = x_reshaped_squeezed.unsqueeze(dim=0) # dim=0 adds dimension at front, dim=1 adds dimension at second position\n",
    "x_reshaped_unsqueezed, x_reshaped_unsqueezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "21372026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.permute rearranges the dimensions of a tensor\n",
    "x_permuted = torch.permute(x_reshaped_unsqueezed, (1, 0))  # switches dimensions 0 and 1\n",
    "x_permuted, x_permuted.shape\n",
    "\n",
    "\n",
    "x_original = torch.randn(size=(224, 224, 3))  # height, width, color_channels (R, G, B)\n",
    "\n",
    "# Permute the original image tensor to rearrange the dimensions to (color_channels, height, width)\n",
    "x_permuted_image = torch.permute(x_original, (2, 0, 1))  # new order: (3, 224, 224)\n",
    "x_permuted_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f97eb2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(676767.), tensor(676767.))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0, 0, 0] = 676767\n",
    "x_original[0, 0, 0], x_permuted_image[0, 0, 0] # change is reflected here too because they share the same memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933f4913",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensors)\n",
    "\n",
    "Indexing with PyTorch is similar to indexing with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790fe103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)  # reshape to (1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c2e2e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on new tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c99a9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the middle bracket (dim=1)\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20d6475a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the inner bracket (dim=2)\n",
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa0609a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use a semicolon to select all dimensions\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7540fea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th and 1st dimension, but only index 1 of 2nd dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a03a9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimensions but only the 1st index of the 1st and 2nd dimensions\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "653c410f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dimensions and all values of 2nd dimension\n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183f22df",
   "metadata": {},
   "source": [
    "## PyTorch tensors & NumPy\n",
    "\n",
    "NumPy is a popular, scientific Python numerical computing library.\n",
    "\n",
    "And because of this, PyTorch has functionality to interact with it.\n",
    "\n",
    "* Data in NumPy, want in PyTorch tensor -> `torch.from_numpy(ndarray`\n",
    "* PyTorch tensor -> Numpy -> `torch.Tensor.numpy()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebd8abc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]), torch.float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning numpy arranys into torch tensors\n",
    "import numpy as np\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array).type(torch.FloatTensor) # float64 -> float32\n",
    "array, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ce879e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype of numpy array is float64 and torch tensor is float32\n",
    "array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1f31f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value of array, what will this do to tensor?\n",
    "array = array + 1\n",
    "array, tensor # tensor will not change because the memory is not shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcde7861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to Numpy array \n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d44ce84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, what happens to numpy_tensor?\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor # tensor will not change because the memory is not shared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abcd9c0",
   "metadata": {},
   "source": [
    "## Reproducibility in PyTorch\n",
    "# Trying to take out the random out of randomness\n",
    "https://youtu.be/V_xro1bcAuA?si=jUmjI4J0efXL3NR9&t=13330\n",
    "\n",
    "In short how a neural network learns:\n",
    "`start with random numbers -> perform tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> again...`\n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**.\n",
    "\n",
    "Essentially what the random seed does is \"flavour\" the randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9be250b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2664, 0.7299, 0.3404],\n",
       "        [0.6605, 0.8059, 0.2243],\n",
       "        [0.8977, 0.4140, 0.7803]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95213e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2629, 0.7150, 0.8681, 0.9870],\n",
      "        [0.7007, 0.4078, 0.2711, 0.3867],\n",
      "        [0.8238, 0.4671, 0.6785, 0.1774]])\n",
      "tensor([[0.5321, 0.7319, 0.4460, 0.1015],\n",
      "        [0.6506, 0.5459, 0.7905, 0.5653],\n",
      "        [0.4043, 0.7565, 0.9185, 0.3320]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8588037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Let's make some random but reproducible tensors\n",
    "\n",
    "# Set the random seed\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED) # declard seed before creating tensor eeach time\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339ec2d",
   "metadata": {},
   "source": [
    "## Running tensors and PyTorch objects on GPUs (faster computations)\n",
    "\n",
    "GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenes to make everything hunky dory lol\n",
    "\n",
    "use `nvidia-smi` to check GPU status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3a2b61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()  # check if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8936949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff8eb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7883a458",
   "metadata": {},
   "source": [
    "For PyTorch since it's capable of running compute on the GPU or CPU, it's best to practice to setup device agnostic code.\n",
    "\n",
    "E.g. run on GPU if available, else run on CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1845849",
   "metadata": {},
   "source": [
    "## 3. Putting tensors (and models) on the GPU\n",
    "\n",
    "The reason we want our tensors/models on the GPU, is becauase GPU results in faster computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54d3cb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (default is CPU)\n",
    "tensor = torch.Tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5e9a9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], device='cuda:0') cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "print(tensor_on_gpu, tensor_on_gpu.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f0eac",
   "metadata": {},
   "source": [
    "### 4. Moving tensors back to the cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88eaac00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If tensor is on GPU, can't transform it to NumPy directly, use tensor.cpu()\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a155a6c",
   "metadata": {},
   "source": [
    "## Exercies & Extra-curriculum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5af0770d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4911],\n",
       "        [2.1696],\n",
       "        [1.5092],\n",
       "        [1.6439],\n",
       "        [2.3490],\n",
       "        [1.4221],\n",
       "        [1.1739]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_1 = torch.rand(7, 7)\n",
    "tensor_2 = torch.rand(1, 7)\n",
    "torch.matmul(tensor_1, tensor_2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3afe42bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5985],\n",
       "        [1.1173],\n",
       "        [1.2741],\n",
       "        [1.6838],\n",
       "        [0.8279],\n",
       "        [1.0347],\n",
       "        [1.2498]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "tensor_1 = torch.rand(7, 7)\n",
    "torch.manual_seed(0)\n",
    "tensor_2 = torch.rand(1, 7)\n",
    "torch.matmul(tensor_1, tensor_2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c36c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "tensor_1 = torch.rand(2, 3).to(device)\n",
    "torch.manual_seed(1234)\n",
    "tensor_2 = torch.rand(2, 3).to(device)\n",
    "output = torch.matmul(tensor_1, tensor_2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9eafdc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6287, device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2606242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2161, device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24f9dcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3, device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6000e5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e25676cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
       "         0.8513]),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)\n",
    "rand_tensor = torch.rand(1, 1, 1, 10)\n",
    "output_rand = rand_tensor.squeeze()\n",
    "output_rand, output_rand.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
